{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_3TWjsJ7bSSA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Colab Notebooks/Deep learning bootcamp/data/shakespeare.txt\""
      ],
      "metadata": {
        "id": "vPlsjS4ReMTE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(path,'r').read()"
      ],
      "metadata": {
        "id": "I2hkwhuUcNHd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj0JkX9neTwt",
        "outputId": "0674fb9d-715d-4db8-84cb-6f862996d53c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(text))\n",
        "print(vocab)\n",
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sb6vEcNeYXK",
        "outputId": "405c17c8-99f5-4a2a-cca0-ca4743b96fbf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '}']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 : Text Processing"
      ],
      "metadata": {
        "id": "C5HW2bR7fKlu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Vectorization"
      ],
      "metadata": {
        "id": "HdkSwPotfVf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_ind = {u:i for i,u in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "48r5J6Mqes9k"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_ind"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ieg5KmmenQq",
        "outputId": "a4747350-1551-4450-b5c0-60e28fe45c96"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " '(': 6,\n",
              " ')': 7,\n",
              " ',': 8,\n",
              " '-': 9,\n",
              " '.': 10,\n",
              " '0': 11,\n",
              " '1': 12,\n",
              " '2': 13,\n",
              " '3': 14,\n",
              " '4': 15,\n",
              " '5': 16,\n",
              " '6': 17,\n",
              " '7': 18,\n",
              " '8': 19,\n",
              " '9': 20,\n",
              " ':': 21,\n",
              " ';': 22,\n",
              " '<': 23,\n",
              " '>': 24,\n",
              " '?': 25,\n",
              " 'A': 26,\n",
              " 'B': 27,\n",
              " 'C': 28,\n",
              " 'D': 29,\n",
              " 'E': 30,\n",
              " 'F': 31,\n",
              " 'G': 32,\n",
              " 'H': 33,\n",
              " 'I': 34,\n",
              " 'J': 35,\n",
              " 'K': 36,\n",
              " 'L': 37,\n",
              " 'M': 38,\n",
              " 'N': 39,\n",
              " 'O': 40,\n",
              " 'P': 41,\n",
              " 'Q': 42,\n",
              " 'R': 43,\n",
              " 'S': 44,\n",
              " 'T': 45,\n",
              " 'U': 46,\n",
              " 'V': 47,\n",
              " 'W': 48,\n",
              " 'X': 49,\n",
              " 'Y': 50,\n",
              " 'Z': 51,\n",
              " '[': 52,\n",
              " ']': 53,\n",
              " '_': 54,\n",
              " '`': 55,\n",
              " 'a': 56,\n",
              " 'b': 57,\n",
              " 'c': 58,\n",
              " 'd': 59,\n",
              " 'e': 60,\n",
              " 'f': 61,\n",
              " 'g': 62,\n",
              " 'h': 63,\n",
              " 'i': 64,\n",
              " 'j': 65,\n",
              " 'k': 66,\n",
              " 'l': 67,\n",
              " 'm': 68,\n",
              " 'n': 69,\n",
              " 'o': 70,\n",
              " 'p': 71,\n",
              " 'q': 72,\n",
              " 'r': 73,\n",
              " 's': 74,\n",
              " 't': 75,\n",
              " 'u': 76,\n",
              " 'v': 77,\n",
              " 'w': 78,\n",
              " 'x': 79,\n",
              " 'y': 80,\n",
              " 'z': 81,\n",
              " '|': 82,\n",
              " '}': 83}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind_to_char = np.array(vocab)"
      ],
      "metadata": {
        "id": "FgEa6XzMeksD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind_to_char"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVMLL1XGf3Cb",
        "outputId": "08479033-236e-41af-8fa9-7b2a4c051e01"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1',\n",
              "       '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?',\n",
              "       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
              "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
              "       '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i',\n",
              "       'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v',\n",
              "       'w', 'x', 'y', 'z', '|', '}'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text = np.array([char_to_ind[c] for c in text])"
      ],
      "metadata": {
        "id": "ZQ3cH6gmf6Et"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(encoded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q_2BXsonIDg",
        "outputId": "f8009c7d-ec78-4380-e85c-e7f59a73c838"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5445609"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFqxZQm1gH4w",
        "outputId": "d141c138-3b2c-4e6a-913d-8879ae132e0d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  1, ..., 30, 39, 29])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = text[:20]\n",
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ob14l0PTgJvS",
        "outputId": "eed6e3b1-ad70-4c34-aed7-1a4924d84a4a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n                   '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skdhsVbngTYS",
        "outputId": "ace14ed1-8048-46c5-dd05-c21604d9c02b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Batches"
      ],
      "metadata": {
        "id": "Z8mHuSe5ga8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGsooLWGgXXP",
        "outputId": "9df0842f-edd3-45e9-9890-8526ad06aa6e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "line = \"From fairest creatures we desire increase\""
      ],
      "metadata": {
        "id": "2oI23bTzgk8x"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1JWfJQqgxlb",
        "outputId": "55931c6d-7860-46d6-8a02-7a23169efabf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "part_stanza = \"\"\"From fairest creatures we desire increase,\n",
        "  That thereby beauty's rose might never die,\n",
        "  But as the riper should by time decease,\"\"\""
      ],
      "metadata": {
        "id": "cQZ8dIsPgzCT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(part_stanza)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jq8MI8j5g1R_",
        "outputId": "a266af6a-1ced-44bc-ecfb-b6850276971d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Sequences"
      ],
      "metadata": {
        "id": "BuIYV06Tg826"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = 120"
      ],
      "metadata": {
        "id": "d_SMU5Oqg6AG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_num_seq = len(text)//(seq_len+1)"
      ],
      "metadata": {
        "id": "ZAG87P0_hFq8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_num_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf08SWwhhL-4",
        "outputId": "75e2098f-6b7d-41bf-9cf0-13c07d9dfa08"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45005"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
        "\n",
        "for i in char_dataset.take(500):\n",
        "  print(ind_to_char[i.numpy()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSQob102hP6T",
        "outputId": "de115e64-be16-4450-abc2-0b4bd4dfd3bc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "1\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "F\n",
            "r\n",
            "o\n",
            "m\n",
            " \n",
            "f\n",
            "a\n",
            "i\n",
            "r\n",
            "e\n",
            "s\n",
            "t\n",
            " \n",
            "c\n",
            "r\n",
            "e\n",
            "a\n",
            "t\n",
            "u\n",
            "r\n",
            "e\n",
            "s\n",
            " \n",
            "w\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            "s\n",
            "i\n",
            "r\n",
            "e\n",
            " \n",
            "i\n",
            "n\n",
            "c\n",
            "r\n",
            "e\n",
            "a\n",
            "s\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "a\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "r\n",
            "e\n",
            "b\n",
            "y\n",
            " \n",
            "b\n",
            "e\n",
            "a\n",
            "u\n",
            "t\n",
            "y\n",
            "'\n",
            "s\n",
            " \n",
            "r\n",
            "o\n",
            "s\n",
            "e\n",
            " \n",
            "m\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "n\n",
            "e\n",
            "v\n",
            "e\n",
            "r\n",
            " \n",
            "d\n",
            "i\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "B\n",
            "u\n",
            "t\n",
            " \n",
            "a\n",
            "s\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "r\n",
            "i\n",
            "p\n",
            "e\n",
            "r\n",
            " \n",
            "s\n",
            "h\n",
            "o\n",
            "u\n",
            "l\n",
            "d\n",
            " \n",
            "b\n",
            "y\n",
            " \n",
            "t\n",
            "i\n",
            "m\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            "c\n",
            "e\n",
            "a\n",
            "s\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "H\n",
            "i\n",
            "s\n",
            " \n",
            "t\n",
            "e\n",
            "n\n",
            "d\n",
            "e\n",
            "r\n",
            " \n",
            "h\n",
            "e\n",
            "i\n",
            "r\n",
            " \n",
            "m\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "b\n",
            "e\n",
            "a\n",
            "r\n",
            " \n",
            "h\n",
            "i\n",
            "s\n",
            " \n",
            "m\n",
            "e\n",
            "m\n",
            "o\n",
            "r\n",
            "y\n",
            ":\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "B\n",
            "u\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "o\n",
            "u\n",
            " \n",
            "c\n",
            "o\n",
            "n\n",
            "t\n",
            "r\n",
            "a\n",
            "c\n",
            "t\n",
            "e\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "o\n",
            "w\n",
            "n\n",
            " \n",
            "b\n",
            "r\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "e\n",
            "y\n",
            "e\n",
            "s\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "F\n",
            "e\n",
            "e\n",
            "d\n",
            "'\n",
            "s\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "l\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            "'\n",
            "s\n",
            " \n",
            "f\n",
            "l\n",
            "a\n",
            "m\n",
            "e\n",
            " \n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            "-\n",
            "s\n",
            "u\n",
            "b\n",
            "s\n",
            "t\n",
            "a\n",
            "n\n",
            "t\n",
            "i\n",
            "a\n",
            "l\n",
            " \n",
            "f\n",
            "u\n",
            "e\n",
            "l\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "M\n",
            "a\n",
            "k\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "a\n",
            " \n",
            "f\n",
            "a\n",
            "m\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "w\n",
            "h\n",
            "e\n",
            "r\n",
            "e\n",
            " \n",
            "a\n",
            "b\n",
            "u\n",
            "n\n",
            "d\n",
            "a\n",
            "n\n",
            "c\n",
            "e\n",
            " \n",
            "l\n",
            "i\n",
            "e\n",
            "s\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "y\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "f\n",
            "o\n",
            "e\n",
            ",\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "s\n",
            "w\n",
            "e\n",
            "e\n",
            "t\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            " \n",
            "t\n",
            "o\n",
            "o\n",
            " \n",
            "c\n",
            "r\n",
            "u\n",
            "e\n",
            "l\n",
            ":\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "o\n",
            "u\n",
            " \n",
            "t\n",
            "h\n",
            "a\n",
            "t\n",
            " \n",
            "a\n",
            "r\n",
            "t\n",
            " \n",
            "n\n",
            "o\n",
            "w\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "o\n",
            "r\n",
            "l\n",
            "d\n",
            "'\n",
            "s\n",
            " \n",
            "f\n",
            "r\n",
            "e\n",
            "s\n",
            "h\n",
            " \n",
            "o\n",
            "r\n",
            "n\n",
            "a\n",
            "m\n",
            "e\n",
            "n\n",
            "t\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "A\n",
            "n\n",
            "d\n",
            " \n",
            "o\n",
            "n\n",
            "l\n",
            "y\n",
            " \n",
            "h\n",
            "e\n",
            "r\n",
            "a\n",
            "l\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "g\n",
            "a\n",
            "u\n",
            "d\n",
            "y\n",
            " \n",
            "s\n",
            "p\n",
            "r\n",
            "i\n",
            "n\n",
            "g\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "W\n",
            "i\n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "o\n",
            "w\n",
            "n\n",
            " \n",
            "b\n",
            "u\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = char_dataset.batch(seq_len+1,drop_remainder=True)"
      ],
      "metadata": {
        "id": "Z5FmE5jMh2bI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_seq_targets(seq):\n",
        "  input_txt = seq[:-1]\n",
        "  target_txt = seq[1:]\n",
        "  return input_txt, target_txt"
      ],
      "metadata": {
        "id": "JUELc1wljFxx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(create_seq_targets)"
      ],
      "metadata": {
        "id": "NuNnzS9hjXBR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_txt, target_txt in dataset.take(1):\n",
        "  print(input_txt.numpy())\n",
        "  print(''.join(ind_to_char[input_txt.numpy()]))\n",
        "  print()\n",
        "  print(target_txt.numpy())\n",
        "  print(''.join(ind_to_char[target_txt.numpy()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWWXLUGPjehw",
        "outputId": "8578ae73-a969-480a-d783-37fc92fe036d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
            "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
            "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
            " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
            " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But\n",
            "\n",
            "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
            "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
            " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
            " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
            "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating training batches"
      ],
      "metadata": {
        "id": "_e9uECwzkVDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "buffer_size = 10000\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size,drop_remainder=True)"
      ],
      "metadata": {
        "id": "V098U6aMkHwb"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aG_r3dkwkpdi",
        "outputId": "047605d0-6b6a-498e-d7e0-e3ec7e54d336"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(128, 120), dtype=tf.int64, name=None), TensorSpec(shape=(128, 120), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the Model"
      ],
      "metadata": {
        "id": "snVIR-1bk0rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "embed_dim = 64\n",
        "rnn_neurons = 1026"
      ],
      "metadata": {
        "id": "Q80WuisQkySs"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,GRU"
      ],
      "metadata": {
        "id": "0OklVFS1k95e"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up Loss Function"
      ],
      "metadata": {
        "id": "l5V-iZdFllbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import sparse_categorical_crossentropy"
      ],
      "metadata": {
        "id": "YpH-TO0VlL1e"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sparse_cat_loss(y_true,y_pred):\n",
        "  return sparse_categorical_crossentropy(y_true,y_pred,from_logits=True)"
      ],
      "metadata": {
        "id": "4-KAsVCzltTp"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(vocab_size,embed_dim,rnn_nerons,batch_size):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size,embed_dim,batch_input_shape=[batch_size,None]))\n",
        "  model.add(GRU(rnn_neurons,return_sequences=True,\n",
        "                stateful=True,recurrent_initializer='glorot_uniform'))\n",
        "  model.add(Dense(vocab_size))\n",
        "\n",
        "  model.compile('adam',loss=sparse_cat_loss)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "VdaAu_lXmFsu"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(vocab_size,embed_dim,rnn_neurons,batch_size)"
      ],
      "metadata": {
        "id": "RtyyNTbjvloo"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFNcGKXwv34e",
        "outputId": "00393b5b-0250-4ca7-94fe-b1c37789c20b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (128, None, 64)           5376      \n",
            "                                                                 \n",
            " gru (GRU)                   (128, None, 1026)         3361176   \n",
            "                                                                 \n",
            " dense (Dense)               (128, None, 84)           86268     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3452820 (13.17 MB)\n",
            "Trainable params: 3452820 (13.17 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Model"
      ],
      "metadata": {
        "id": "ExuxDRhRxg_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"<==(batch_size,sequence_length,vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sxn1fY3hxehi",
        "outputId": "6b8c9d39-1229-425e-a77e-a7dfb15fb24b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 120, 84) <==(batch_size,sequence_length,vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOWAk98dyP4F",
        "outputId": "c7996f91-18ae-48b4-82a9-20594bb849d3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128, 120, 84), dtype=float32, numpy=\n",
              "array([[[-6.8441760e-03,  6.5293112e-03, -5.7583414e-03, ...,\n",
              "          6.5148198e-03, -6.3490524e-04, -4.1530649e-03],\n",
              "        [-4.9437128e-04,  6.5458510e-03, -1.1687280e-03, ...,\n",
              "          4.5698797e-03, -7.6071974e-03, -2.1359727e-03],\n",
              "        [-8.9640506e-03,  7.7757979e-04, -9.1471308e-04, ...,\n",
              "         -1.5221634e-03, -1.2192574e-02, -8.3983680e-03],\n",
              "        ...,\n",
              "        [-1.7940054e-04,  7.6958421e-04, -3.6414247e-03, ...,\n",
              "          8.0466847e-04, -4.7672475e-03, -4.4003972e-03],\n",
              "        [-4.5002527e-03,  3.4668024e-03, -1.1800140e-03, ...,\n",
              "         -5.6407349e-03, -1.2624991e-03, -3.2684370e-03],\n",
              "        [-5.2871276e-03,  5.4416428e-03, -9.0950671e-05, ...,\n",
              "         -7.8130728e-03,  1.2253773e-03, -3.1532783e-03]],\n",
              "\n",
              "       [[ 3.0288190e-04, -2.0513099e-03,  6.2405779e-03, ...,\n",
              "         -1.2474265e-03, -7.1879753e-05,  1.5124838e-03],\n",
              "        [ 4.4252668e-03,  1.0573687e-03,  2.3814463e-03, ...,\n",
              "          5.6002685e-03, -2.1477181e-03,  1.8165600e-03],\n",
              "        [-2.0003961e-03,  4.3197330e-03,  4.2224803e-04, ...,\n",
              "          5.7515232e-03, -2.7680565e-03, -4.2184996e-03],\n",
              "        ...,\n",
              "        [ 4.2418377e-03, -6.6013221e-04, -3.3836002e-03, ...,\n",
              "          6.9625899e-03, -4.6958984e-03, -5.1301294e-03],\n",
              "        [-5.9178229e-03, -1.8349116e-03, -3.3130450e-04, ...,\n",
              "          6.1713769e-03, -4.5069228e-03, -4.1864277e-04],\n",
              "        [-6.2657273e-03, -7.0343155e-04, -2.8625939e-03, ...,\n",
              "          4.0495987e-03, -5.9929094e-03, -2.3846333e-03]],\n",
              "\n",
              "       [[ 2.6625826e-03,  3.5162247e-03,  1.7396582e-03, ...,\n",
              "          1.4729301e-03, -7.0718457e-03,  3.0033401e-05],\n",
              "        [ 5.2607190e-03, -1.5171213e-03, -3.1284580e-04, ...,\n",
              "          1.9900147e-03, -3.6333688e-03, -6.6615557e-03],\n",
              "        [ 4.0893154e-03,  1.6092339e-03,  1.5016017e-03, ...,\n",
              "          4.1435515e-03, -6.7889638e-04, -2.2343958e-03],\n",
              "        ...,\n",
              "        [-8.1523629e-03,  2.4319100e-03,  5.8156811e-04, ...,\n",
              "          3.9049421e-04, -6.5516206e-03, -6.4209229e-03],\n",
              "        [-6.1037000e-03,  4.3689282e-04, -1.4100281e-04, ...,\n",
              "          3.8297768e-03, -3.4649610e-03, -5.9305644e-03],\n",
              "        [-6.6953390e-03,  1.3453733e-03,  2.8631615e-03, ...,\n",
              "          9.3479911e-03, -5.6943097e-03, -1.6338620e-03]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-6.8441760e-03,  6.5293112e-03, -5.7583414e-03, ...,\n",
              "          6.5148198e-03, -6.3490524e-04, -4.1530649e-03],\n",
              "        [-4.9437128e-04,  6.5458510e-03, -1.1687280e-03, ...,\n",
              "          4.5698797e-03, -7.6071974e-03, -2.1359727e-03],\n",
              "        [ 7.6428631e-05,  2.8012923e-03, -2.4267023e-03, ...,\n",
              "         -4.7942875e-03, -5.0544804e-03, -4.0063574e-03],\n",
              "        ...,\n",
              "        [-5.2681740e-04,  1.8413948e-03, -7.8301854e-04, ...,\n",
              "         -1.1343076e-05, -5.5326931e-03, -3.8613990e-04],\n",
              "        [ 1.2296118e-03, -4.0690036e-04, -5.7422573e-04, ...,\n",
              "          3.6062896e-03, -3.3065241e-03, -4.7432869e-03],\n",
              "        [-8.4497808e-03,  9.0668350e-04,  3.8533832e-03, ...,\n",
              "         -1.0444869e-03, -7.9141296e-03, -7.1215472e-04]],\n",
              "\n",
              "       [[ 7.7472655e-03,  4.6639573e-03,  5.4355350e-04, ...,\n",
              "         -1.5340371e-03, -2.5176448e-03, -4.3159144e-04],\n",
              "        [ 6.2463293e-03, -4.0407060e-04, -1.3361819e-03, ...,\n",
              "          5.9094175e-04, -1.8146170e-03, -4.8827208e-03],\n",
              "        [-7.0727519e-03,  1.7362608e-03, -2.4703087e-03, ...,\n",
              "         -1.6441637e-04, -7.5632739e-03, -3.5692772e-03],\n",
              "        ...,\n",
              "        [-5.2913898e-03,  8.1216255e-03,  2.3788249e-03, ...,\n",
              "         -5.9175561e-04, -4.4127842e-03, -4.6126889e-03],\n",
              "        [ 1.0152662e-03,  7.8617356e-04, -7.4059912e-04, ...,\n",
              "          1.0468741e-03, -1.6336424e-03, -7.3256581e-03],\n",
              "        [-2.8762864e-03,  1.3133149e-03, -2.8359920e-03, ...,\n",
              "          1.9613826e-03, -3.9898232e-03, -5.8596185e-03]],\n",
              "\n",
              "       [[-2.0725175e-03, -3.1169376e-03, -5.6440401e-04, ...,\n",
              "         -7.6509584e-03, -1.6598596e-03, -6.4735981e-03],\n",
              "        [ 1.1338737e-03,  1.4829357e-03,  7.0088729e-04, ...,\n",
              "         -1.6895734e-03,  6.6326355e-04, -1.4699886e-03],\n",
              "        [ 3.9216955e-03, -2.7587730e-03, -1.1091732e-03, ...,\n",
              "          1.2184581e-03,  1.9137431e-03, -7.1840016e-03],\n",
              "        ...,\n",
              "        [ 1.5885053e-03,  3.8766207e-03,  2.5079295e-03, ...,\n",
              "          7.0372503e-03,  1.6874264e-03, -2.2144399e-03],\n",
              "        [ 3.9208010e-03,  1.5802593e-03, -4.7765477e-03, ...,\n",
              "          7.1876417e-03,  7.2023352e-03, -7.4569811e-03],\n",
              "        [ 7.5788465e-03, -4.8743706e-04, -3.4435927e-03, ...,\n",
              "          1.8470807e-03,  7.4772828e-04, -4.1458742e-03]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples_indices = tf.random.categorical(example_batch_predictions[0],num_samples=1)"
      ],
      "metadata": {
        "id": "28MKqZWUyL4k"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IA7N0-qylGo",
        "outputId": "62974686-548f-4a03-c52c-987ff0326de5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(120, 1), dtype=int64, numpy=\n",
              "array([[14],\n",
              "       [70],\n",
              "       [26],\n",
              "       [18],\n",
              "       [16],\n",
              "       [53],\n",
              "       [19],\n",
              "       [74],\n",
              "       [75],\n",
              "       [45],\n",
              "       [56],\n",
              "       [74],\n",
              "       [ 2],\n",
              "       [53],\n",
              "       [61],\n",
              "       [75],\n",
              "       [49],\n",
              "       [67],\n",
              "       [32],\n",
              "       [22],\n",
              "       [24],\n",
              "       [63],\n",
              "       [30],\n",
              "       [68],\n",
              "       [44],\n",
              "       [48],\n",
              "       [40],\n",
              "       [17],\n",
              "       [ 5],\n",
              "       [67],\n",
              "       [74],\n",
              "       [57],\n",
              "       [27],\n",
              "       [67],\n",
              "       [ 4],\n",
              "       [30],\n",
              "       [80],\n",
              "       [20],\n",
              "       [ 6],\n",
              "       [78],\n",
              "       [41],\n",
              "       [12],\n",
              "       [21],\n",
              "       [68],\n",
              "       [74],\n",
              "       [51],\n",
              "       [11],\n",
              "       [ 3],\n",
              "       [33],\n",
              "       [51],\n",
              "       [61],\n",
              "       [69],\n",
              "       [53],\n",
              "       [ 5],\n",
              "       [14],\n",
              "       [51],\n",
              "       [82],\n",
              "       [31],\n",
              "       [16],\n",
              "       [40],\n",
              "       [30],\n",
              "       [29],\n",
              "       [62],\n",
              "       [41],\n",
              "       [26],\n",
              "       [26],\n",
              "       [63],\n",
              "       [50],\n",
              "       [30],\n",
              "       [57],\n",
              "       [28],\n",
              "       [47],\n",
              "       [62],\n",
              "       [17],\n",
              "       [55],\n",
              "       [51],\n",
              "       [41],\n",
              "       [ 9],\n",
              "       [26],\n",
              "       [38],\n",
              "       [76],\n",
              "       [31],\n",
              "       [21],\n",
              "       [82],\n",
              "       [ 8],\n",
              "       [ 7],\n",
              "       [32],\n",
              "       [42],\n",
              "       [68],\n",
              "       [34],\n",
              "       [50],\n",
              "       [ 5],\n",
              "       [75],\n",
              "       [49],\n",
              "       [50],\n",
              "       [60],\n",
              "       [22],\n",
              "       [10],\n",
              "       [56],\n",
              "       [83],\n",
              "       [ 4],\n",
              "       [28],\n",
              "       [29],\n",
              "       [ 1],\n",
              "       [23],\n",
              "       [ 3],\n",
              "       [80],\n",
              "       [ 4],\n",
              "       [53],\n",
              "       [42],\n",
              "       [20],\n",
              "       [24],\n",
              "       [51],\n",
              "       [79],\n",
              "       [51],\n",
              "       [72],\n",
              "       [70],\n",
              "       [66],\n",
              "       [ 6],\n",
              "       [18]])>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.squeeze(samples_indices,axis=1).numpy()"
      ],
      "metadata": {
        "id": "g6BlsGwuypUp"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMhtJFTHzDwq",
        "outputId": "d6b3bb99-249d-45a2-dd82-089fe8154ece"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([14, 70, 26, 18, 16, 53, 19, 74, 75, 45, 56, 74,  2, 53, 61, 75, 49,\n",
              "       67, 32, 22, 24, 63, 30, 68, 44, 48, 40, 17,  5, 67, 74, 57, 27, 67,\n",
              "        4, 30, 80, 20,  6, 78, 41, 12, 21, 68, 74, 51, 11,  3, 33, 51, 61,\n",
              "       69, 53,  5, 14, 51, 82, 31, 16, 40, 30, 29, 62, 41, 26, 26, 63, 50,\n",
              "       30, 57, 28, 47, 62, 17, 55, 51, 41,  9, 26, 38, 76, 31, 21, 82,  8,\n",
              "        7, 32, 42, 68, 34, 50,  5, 75, 49, 50, 60, 22, 10, 56, 83,  4, 28,\n",
              "       29,  1, 23,  3, 80,  4, 53, 42, 20, 24, 51, 79, 51, 72, 70, 66,  6,\n",
              "       18])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Given the input seq: \")\n",
        "print(\"\".join(ind_to_char[input_example_batch[0]]))\n",
        "print()\n",
        "print(\"Next Char Predictions: \")\n",
        "print(\"\".join(ind_to_char[sampled_indices]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdpZ_rOHzGL9",
        "outputId": "95b0523f-31ea-495d-cd24-4321d3a91ac0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given the input seq: \n",
            "are three\n",
            "    That Rome should dote on; yet, by the faith of men,\n",
            "    We have some old crab trees here at home that will\n",
            "\n",
            "Next Char Predictions: \n",
            "3oA75]8stTas!]ftXlG;>hEmSWO6'lsbBl&Ey9(wP1:msZ0\"HZfn]'3Z|F5OEDgPAAhYEbCVg6`ZP-AMuF:|,)GQmIY'tXYe;.a}&CD <\"y&]Q9>ZxZqok(7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30"
      ],
      "metadata": {
        "id": "SY7VSt_7zk41"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "cghnSO071NdJ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='loss',patience=2)"
      ],
      "metadata": {
        "id": "Az-0emO81Feb"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(dataset,epochs=epochs,callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN8bXxgLzqtC",
        "outputId": "36ebeae7-d31e-4d61-f00d-e8768a87082d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "351/351 [==============================] - 45s 124ms/step - loss: 1.5220\n",
            "Epoch 2/30\n",
            "351/351 [==============================] - 48s 130ms/step - loss: 1.3685\n",
            "Epoch 3/30\n",
            "351/351 [==============================] - 50s 137ms/step - loss: 1.2924\n",
            "Epoch 4/30\n",
            "351/351 [==============================] - 50s 138ms/step - loss: 1.2465\n",
            "Epoch 5/30\n",
            "351/351 [==============================] - 51s 139ms/step - loss: 1.2137\n",
            "Epoch 6/30\n",
            "351/351 [==============================] - 50s 138ms/step - loss: 1.1885\n",
            "Epoch 7/30\n",
            "351/351 [==============================] - 51s 138ms/step - loss: 1.1673\n",
            "Epoch 8/30\n",
            "351/351 [==============================] - 51s 138ms/step - loss: 1.1490\n",
            "Epoch 9/30\n",
            "351/351 [==============================] - 51s 138ms/step - loss: 1.1322\n",
            "Epoch 10/30\n",
            "351/351 [==============================] - 51s 140ms/step - loss: 1.1177\n",
            "Epoch 11/30\n",
            "351/351 [==============================] - 50s 136ms/step - loss: 1.1044\n",
            "Epoch 12/30\n",
            "351/351 [==============================] - 51s 139ms/step - loss: 1.0908\n",
            "Epoch 13/30\n",
            "351/351 [==============================] - 50s 138ms/step - loss: 1.0788\n",
            "Epoch 14/30\n",
            "351/351 [==============================] - 51s 138ms/step - loss: 1.0677\n",
            "Epoch 15/30\n",
            "351/351 [==============================] - 51s 140ms/step - loss: 1.0563\n",
            "Epoch 16/30\n",
            "351/351 [==============================] - 50s 136ms/step - loss: 1.0462\n",
            "Epoch 17/30\n",
            "351/351 [==============================] - 51s 139ms/step - loss: 1.0357\n",
            "Epoch 18/30\n",
            "351/351 [==============================] - 52s 141ms/step - loss: 1.0271\n",
            "Epoch 19/30\n",
            "351/351 [==============================] - 51s 136ms/step - loss: 1.0184\n",
            "Epoch 20/30\n",
            "351/351 [==============================] - 51s 141ms/step - loss: 1.0108\n",
            "Epoch 21/30\n",
            "351/351 [==============================] - 52s 140ms/step - loss: 1.0036\n",
            "Epoch 22/30\n",
            "351/351 [==============================] - 51s 140ms/step - loss: 0.9969\n",
            "Epoch 23/30\n",
            "351/351 [==============================] - 50s 136ms/step - loss: 0.9916\n",
            "Epoch 24/30\n",
            "351/351 [==============================] - 51s 139ms/step - loss: 0.9858\n",
            "Epoch 25/30\n",
            "351/351 [==============================] - 52s 141ms/step - loss: 0.9806\n",
            "Epoch 26/30\n",
            "351/351 [==============================] - 50s 136ms/step - loss: 0.9769\n",
            "Epoch 27/30\n",
            "351/351 [==============================] - 51s 139ms/step - loss: 0.9730\n",
            "Epoch 28/30\n",
            "351/351 [==============================] - 51s 138ms/step - loss: 0.9696\n",
            "Epoch 29/30\n",
            "351/351 [==============================] - 51s 140ms/step - loss: 0.9663\n",
            "Epoch 30/30\n",
            "351/351 [==============================] - 51s 139ms/step - loss: 0.9641\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b5aa9cc47c0>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Text"
      ],
      "metadata": {
        "id": "j4ALj-eO8zvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('shakespeare_gen_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4ot4Seo0A4j",
        "outputId": "3217c47a-1643-4100-85d4-577de836c90f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "zv83OtiB87K_"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(vocab_size,embed_dim,rnn_neurons,batch_size=1)\n",
        "model.load_weights('shakespeare_gen_model.h5')\n",
        "model.build(tf.TensorShape([1,None]))"
      ],
      "metadata": {
        "id": "BrMfDjR58_yb"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6yk0LMb9lNn",
        "outputId": "71c3fad4-9fb7-4894-d549-4640a67f574b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (1, None, 64)             5376      \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (1, None, 1026)           3361176   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (1, None, 84)             86268     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3452820 (13.17 MB)\n",
            "Trainable params: 3452820 (13.17 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model,start_seed,gen_size=100,temp=1.0):\n",
        "  num_generate = gen_size\n",
        "  input_eval = [char_to_ind[s] for s in start_seed]\n",
        "  input_eval = tf.expand_dims(input_eval,0)\n",
        "\n",
        "  text_generated = []\n",
        "  temperature = temp\n",
        "\n",
        "  model.reset_states()\n",
        "\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "\n",
        "    predictions = tf.squeeze(predictions,0)\n",
        "\n",
        "    predictions = predictions/temperature\n",
        "    predicted_id = tf.random.categorical(predictions,num_samples=1)[-1,0].numpy()\n",
        "\n",
        "    input_eval = tf.expand_dims([predicted_id],0)\n",
        "    text_generated.append(ind_to_char[predicted_id])\n",
        "  return (start_seed+''.join(text_generated))"
      ],
      "metadata": {
        "id": "3hesR1u59qUA"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model,\"flower\",gen_size=1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bDco2Yr-7PE",
        "outputId": "a39ed9d8-3ea0-4234-ff81-f5c80548cd91"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flowers in hurts do it reck)\n",
            "    To book and run and watch your presence?\n",
            "    Ay, and with the life of petitions well,\n",
            "    Yet now less in one part flated out,\n",
            "    Look'd winds do oats; for leaving she alone\n",
            "    Upon the heart of Roderigence of Protector. Dost thou know againe the sum of my\n",
            "    and flats! come away.\n",
            "  APEMANTUS. These natural spirit is mistress of peace, yet love\n",
            "    The slaves of Rome, thy life.\n",
            "  LUCIUS' SERVANT. My lady's chamber.\n",
            "    Farewell, discretion; from thy words cont gods,\n",
            "    How much I am anwelth! And then ke found,\n",
            "    To give thee gallows than either the winds\n",
            "    Of gomand, his forkness him; and on it holds his looks\n",
            "    The very favour with as news as longer,\n",
            "    And in conclusion with the crown a poise\n",
            "    Shall itches with a divorce of love,\n",
            "    Call'st wit good nature by side lone,\n",
            "    We find her out within these tears\n",
            "    To cure their suits you have a chuck affections.\n",
            "  DUKE. Are not you joint for?\n",
            "  CLOWN. I will require you a man to prove for an is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model,\"JULIET\",gen_size=1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsM3EK3E_5iB",
        "outputId": "d0461828-2fa9-4fdf-f887-627c65e26a92"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JULIET AARON. What is the fool; I have done undone do expours.\n",
            "    But welcome, doth the Queen of news are just.  \n",
            "  GLOUCESTER. Advance, starve after this. Return with himself\n",
            "    When I walk o'er with curs and yours, let me forth ye\n",
            "    The first: were left immortal garter.\n",
            "  Nurse. So please you, sir, this love that sought your honour I'll repent the meat.\n",
            "  POLIXENES. If we\n",
            "                       YOUERGRO\n",
            "  HORTENSIO. Grest, was's he these gamer\n",
            " s of latents of warlike rogue's other way.  \n",
            "\n",
            "               Enter PATROCLUS\n",
            "\n",
            "  PRIAM SHYLOCK. Marry, with confounded bought against them?\n",
            "    Or who knew of his fee?\n",
            "    Where be it minst thou fought against my youth,\n",
            "    Shall Hasting deep, which was a many's life.\n",
            "\n",
            "                              Enter MALVOLIO\n",
            "\n",
            "  MALVOLIO. My lords, withal\n",
            "    Am given me than in marrows over present\n",
            "    A merchatch'd opinion, and their ears ale strong,\n",
            "    Puts hither to ashore;\n",
            "    Not here so much   Your mistress saw you Duke of March. What's the matter?\n",
            "  \n"
          ]
        }
      ]
    }
  ]
}